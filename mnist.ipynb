{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.python.keras.datasets import mnist\n",
    "from tensorflow.python.keras.layers import Input, Flatten, Dense, Activation, Conv2D, MaxPool2D\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.optimizers import SGD\n",
    "from tensorflow.python.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "TIMESTAMP = int(time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregamos os dados já embaralhados divididos em train e test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passamos as entradas pra `float` (pra poder manipular), adicionamos a dimensão do canal e pré-tratamos.\n",
    "\n",
    "Como temos um intervalo definido de entrada `[0, 255]`, simplesmente mudamos a escala para `[0, 1]`, o que é bem comum de se fazer em imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passamos os labels pra one-hot encoding (vetor 10-dimensional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camada de entrada (compatível com a forma de x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = entry = Input(shape=x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Opcional)* Camada de convolução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Conv2D(32, kernel_size=3, strides=1)(out)\n",
    "out = Activation('relu')(out)\n",
    "out = MaxPool2D()(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos o tensor em um vetor unidimensional. Isso  é necessário para podermos aplicar uma camada densa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Flatten()(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(Opcional)* Camada intermediária"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = Dense(20)(out)\n",
    "out = Activation('relu')(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camada de saída com 10 neurônios, cada um responsável por um dígito e aplicação do softmax para obtermos uma distribuição de probabilidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0926 13:08:11.557226 140180278683456 deprecation.py:506] From /usr/local/google/home/grovina/.local/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "out = Dense(10)(out)\n",
    "out = Activation('softmax')(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição do modelo em si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model(entry, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos a descrição do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição do custo e da otimização\n",
    "Custo é a cross-entropia entre saída e resposta\n",
    "Otimização é a descida de gradientes estocástica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=SGD(lr=0.01, momentum=0.9, nesterov=True),\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento em si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.3348 - acc: 0.9061 - val_loss: 0.3046 - val_acc: 0.9149\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.3125 - acc: 0.9122 - val_loss: 0.2951 - val_acc: 0.9207\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.3010 - acc: 0.9161 - val_loss: 0.2881 - val_acc: 0.9188\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2933 - acc: 0.9180 - val_loss: 0.2825 - val_acc: 0.9205\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 26us/sample - loss: 0.2878 - acc: 0.9200 - val_loss: 0.2808 - val_acc: 0.9213\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2838 - acc: 0.9200 - val_loss: 0.2768 - val_acc: 0.9221\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2798 - acc: 0.9218 - val_loss: 0.2752 - val_acc: 0.9231\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2773 - acc: 0.9223 - val_loss: 0.2737 - val_acc: 0.9227\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.2747 - acc: 0.9232 - val_loss: 0.2732 - val_acc: 0.9236\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2727 - acc: 0.9237 - val_loss: 0.2722 - val_acc: 0.9234\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 0.2707 - acc: 0.9245 - val_loss: 0.2730 - val_acc: 0.9230\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2690 - acc: 0.9249 - val_loss: 0.2722 - val_acc: 0.9229\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2674 - acc: 0.9260 - val_loss: 0.2700 - val_acc: 0.9239\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2665 - acc: 0.9256 - val_loss: 0.2700 - val_acc: 0.9249\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.2650 - acc: 0.9263 - val_loss: 0.2733 - val_acc: 0.9243\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 24us/sample - loss: 0.2639 - acc: 0.9265 - val_loss: 0.2692 - val_acc: 0.9244\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.2626 - acc: 0.9274 - val_loss: 0.2679 - val_acc: 0.9226\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.2617 - acc: 0.9273 - val_loss: 0.2682 - val_acc: 0.9228\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.2611 - acc: 0.9276 - val_loss: 0.2676 - val_acc: 0.9239\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 23us/sample - loss: 0.2602 - acc: 0.9285 - val_loss: 0.2701 - val_acc: 0.9244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7dd41c4358>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=60,\n",
    "    epochs=20,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('save/mnist.{epoch:02d}.h5'),\n",
    "        TensorBoard(log_dir='logs/mnist_{}'.format(TIMESTAMP))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carrega a imagem, converte para escala de cinza e redimensiona para o tamanho da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_img('data/5.png', color_mode='grayscale', target_size=net.input_shape[1:])\n",
    "answer = to_categorical(5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.choice(len(x_test))\n",
    "image, answer = x_test[i], y_test[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria a entrada e infere a saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.reshape(image, (1, 28, 28, 1))\n",
    "y = net.predict(x, verbose=0)[0]\n",
    "\n",
    "plt.imshow(x[0, ..., 0], cmap='gray')\n",
    "plt.show()\n",
    "print('A rede diz:', np.argmax(y))\n",
    "print('Gabarito:', np.argmax(answer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
